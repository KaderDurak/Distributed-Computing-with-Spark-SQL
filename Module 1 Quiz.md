Question 1
Which of the following are true when it comes to the business value of big data? (Select all that apply.)


  **The size of the data businesses collect is growing**


 **Businesses are increasingly making data-driven decisions**


  Automated technologies mean that data scientists and data analysts are no longer needed


Question 2
Spark uses...

(Select all that apply.)

Your database technology (e.g., Postgres or SQL Server) to run Spark queries


 **A driver node to distribute work across a number of executor nodes**


 **A distributed cluster of networked computers made of a driver node and many executor nodes**



 One very large computer that is able to run computation against large databases


 A distributed cluster of networked computers made of many driver nodes and many executor nodes


Question 3
How does Spark execute code backed by DataFrames? (Select all that apply.)

 It executes code determined in advance


 It iterates over all of the source data to exhaustively evaluate queries


 **It separates the "logical plan" of what you want to accomplish from the "physical plan" of how to do it so it can optimize the query**

 **It optimizes your query by figuring out the best "how" to execute what you want**


Question 4
What are the properties of Spark DataFrames? (Select all that apply.)

 **Dataset: Collection of partitioned data**

 **Resilient: Fault-tolerant**

 Tables: Operates as any table in SQL environments


 **Distributed: Computed across multiple nodes**



Question 5
What is the difference between Spark and database technologies? (Select all that apply.)


 **Spark is a computation engine and is not for data storage**

 Spark does not interact with databases but uses its proprietary DataFrame technology instead

 Spark operates for both data storage and computation

 **Spark is a highly optimized compute engine and is not a database**

 Spark in an alternative to traditional databases


Question 6
What is Amdahl's law of scalability? (Select all that apply.)


 **Amdahl's law states that the speedup of a task is a function of how much of that task can be parallelized**

 A formula that gives the expected speed of a single processor performing a computation

 A formula that gives the theoretical speedup as a function of the size of a partition (or subset) of data

 A formula that gives the number of processors (or other unit of parallelism) needed to complete a task

 **A formula that gives the theoretical speedup as a function of the percentage of a computation that can be parallelized**


Question 7
Spark offers a unified approach to analytics. What does this include? (Select all that apply.)


 **Spark unifies applications such as SQL queries, streaming, and machine learning**

 Spark unifies databases with optimized computation allowing for faster computation against the data it stores

 **Spark allows analysts, data scientists, and data engineers to all use the same core technology**

 Spark is able to connect to data where it lives in any number of sources, unifying the components of a data application

 **Spark code can be written in the following languages: SQL, Scala, Java, Python, and R**


Question 8
What is a Databricks notebook?

 A Spark instance that executes queries

 A cluster that executes Spark code

 **A collaborative, interactive workspace that allows you to execute Spark queries at scale**

 A single Spark query



Question 9
How can you get data into Databricks? (Select all that apply.)


 **By uploading it through the user interface**

 **By registering the data as a table**

 By connecting to Dropbox or Google Drive

 **By "mounting" data backed by cloud storage**


Question 10
What are the qualities of big data? (Select all that apply.)



 **Volume: the amount of data**

 Valorous: the positives impact of data


 **Variety: the diversity of data**

 **Velocity: the speed of data**

 **Veracity: the reliability of data**



