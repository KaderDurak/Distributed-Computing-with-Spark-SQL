Question 1
Decoupling storage and compute means storing data in one location and processing it using a separate resource. What are the benefits of this design principle? (Select all that apply.)


+ It makes updates to new software versions easier

+ Resources are isolated and therefore more manageable and debuggable

It results in copies of the data in case of a data center outage

+ It allows for elastic resources so larger storage or compute resources are used only when needed


Question 2
You want to run a report entailing summary statistics on a large dataset sitting in a database. What is the main resource limitation of this task?

CPU: the transfer of data is more demanding than the computation

IO: computation is more demanding that the data transfer

CPU: computation is more demanding than the data transfer

+ IO: the transfer of data is more demanding than the computation

Question 3
Processing virtual shopping cart orders in real time is an example of...

Online Analytical Processing (OLAP)

+ Online Transaction Processing (OLTP)


Question 4
When are BLOB stores an appropriate place to store data? (Select all that apply.)



+ For cheap storage

+ For a "data lake" of largely unstructured data

+ For storing large files

For online transaction processing on a website


Question 5
JDBC is the standard protocol for interacting with databases in the Java environment. How do parallel connections work between Spark and a database using JDBC?



Specify the number of partitions using COALESCE. Spark then creates one parallel connection for each partition.


Specify the numPartitions configuration setting. Spark then creates one parallel connection for each partition.


+ Specify a column, number of partitions, and the column's minimum and maximum values. Spark then divides that range of values between parallel connections.*****


Specify the number of partitions using REPARTITION. Spark then creates one parallel connection for each partition.


Question 6
What are some of the advantages of the file format Parquet over CSV? (Select all that apply.)


+ Compression

Corruptible

+ Parallelism

+ Columnar


Question 7
SQL is normally used to query tabular (or "structured") data. Semi-structured data like JSON is common in big data environments. Why? (Select all that apply.)


+ It allows for missing data

+ It allows for complex data types

+ It allows for data change over time

+ It does not need a formal structure*****

It allows for easy joins between relational JSON tables


Question 8
Data writes in Spark can happen in serial or in parallel. What controls this parallelism?


+ The number of data partitions in a DataFrame

The number of jobs in a write operation

The number of stages in a write operation

The numPartitions setting in the Spark configuration


Question 9
Fill in the blanks with the appropriate response below: 

A _______ table manages _______and a DROP TABLE command will result in data loss.



Unmanaged, both the data and metadata such as the schema and data location


+ Managed, both the data and metadata such as the schema and data location


Managed, only the metadata such as the schema and data location


Unmanaged, only the metadata such as the schema and data location
